{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jfcskxZU5bWA"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter,defaultdict\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kxIsgiOw873r"
   },
   "outputs": [],
   "source": [
    "with open('D:/Squad/train.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open('D:/Squad/dev.json') as f:\n",
    "    test_data=json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0PSmVi7Di1Iw"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"spacy\", language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m-BJxPhYUyNi"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['id','title','context','question','answer'])\n",
    "for topic in data[\"data\"]:\n",
    "  for paragraph in topic[\"paragraphs\"]:\n",
    "    for context in paragraph[\"qas\"]:\n",
    "      df = df.append({'id':context[\"id\"], 'title':topic[\"title\"],'context':paragraph[\"context\"],'question':context[\"question\"],'answer':context[\"answers\"][0]['text']}, ignore_index=True)\n",
    "\n",
    "test_df = pd.DataFrame(columns=['id','title','context','question','answer'])\n",
    "for topic in test_data[\"data\"]:\n",
    "  for paragraph in topic[\"paragraphs\"]:\n",
    "    for context in paragraph[\"qas\"]:\n",
    "      df = df.append({'id':context[\"id\"], 'title':topic[\"title\"],'context':paragraph[\"context\"],'question':context[\"question\"],'answer':context[\"answers\"][0]['text']}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QP9NO0Ht-mLL"
   },
   "outputs": [],
   "source": [
    "unique_context_df=pd.DataFrame(df['context'].unique(),columns=['context'])\n",
    "question_context_df=pd.DataFrame(df['question'].unique(),columns=['question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R_5e3T7JSQGi"
   },
   "outputs": [],
   "source": [
    "dict_context = []\n",
    "char_context=[]\n",
    "ques_context=[]\n",
    "char_question=[]\n",
    "for i in range(len(unique_context_df)):\n",
    "  dict_context.extend(list(tokenizer(unique_context_df['context'][i].lower().strip())))\n",
    "  for word in list(tokenizer(unique_context_df['context'][i].lower().strip())):\n",
    "    char_context.extend(list(word))\n",
    "for i in range(len(question_context_df)):\n",
    "  ques_context.extend(list(tokenizer(question_context_df['question'][i].lower().strip())))\n",
    "  for word in list(tokenizer(question_context_df['question'][i].lower().strip())):\n",
    "    char_question.extend(list(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3h0_29ZQMMpb"
   },
   "outputs": [],
   "source": [
    "vocab=[]\n",
    "char=[]\n",
    "vocab.append('pad')\n",
    "vocab.append('unk')\n",
    "char.append('pad')\n",
    "char.append('unk')\n",
    "vocab.extend(list(Counter(list(Counter(dict_context).keys())+list(Counter(ques_context).keys())).keys()))\n",
    "char.extend(list(Counter(list(Counter(char_context).keys())+list(Counter(char_question).keys())).keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M6McOTGFv1eP"
   },
   "outputs": [],
   "source": [
    "word2idx = defaultdict(lambda:1)\n",
    "i=0;\n",
    "for z in vocab:\n",
    "    word2idx[z]=i;\n",
    "    i=i+1;\n",
    "\n",
    "char2idx = defaultdict(lambda:1)\n",
    "i=0;\n",
    "for z in char:\n",
    "    char2idx[z]=i;\n",
    "    i=i+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Es8YSjHclD3m"
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "glove = GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=100\n",
    "word_embedding = np.zeros((len(vocab),embedding_dim))\n",
    "for i, word in enumerate(vocab):\n",
    "    word_embedding[i] = glove[word]\n",
    "\n",
    "word_embedding=torch.Tensor(word_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_e4Yud7fhgQJ"
   },
   "outputs": [],
   "source": [
    "class Question_Answer(Dataset):\n",
    "    def __init__(self,data,tokenizer,glove):\n",
    "        self.data= data;\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context=self.data['context'][idx]\n",
    "        line = context.lower().strip()\n",
    "        tokens = self.tokenizer(line)\n",
    "        context_data = torch.tensor([word2idx[x] for x in tokens])\n",
    "        \n",
    "        question=self.data['question'][idx]\n",
    "        tks=self.tokenizer(question.lower().strip())\n",
    "        question_data = torch.tensor([word2idx[x] for x in tks])\n",
    "        \n",
    "        answer=self.data['answer'][idx]\n",
    "        tks=self.tokenizer(answer.lower().strip())\n",
    "        answer_data = torch.tensor([word2idx[x] for x in tks])\n",
    "        \n",
    "        return context_data, question_data, answer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EHqBNr3x40xo"
   },
   "outputs": [],
   "source": [
    "def padding_and_masking(batch):\n",
    "    context, question, answer = zip(*batch)\n",
    "    context_seq_length=torch.tensor([len(x) for x in context])\n",
    "    question_seq_length=torch.tensor([len(x) for x in question])\n",
    "    answer_seq_length=torch.tensor([len(x) for x in answer])\n",
    "    \n",
    "    context = pad_sequence(context, batch_first=True, padding_value=0)\n",
    "    question=pad_sequence(question, batch_first=True, padding_value=0)\n",
    "    answer=pad_sequence(answer, batch_first=True, padding_value=0)\n",
    "    \n",
    "\n",
    "    return context, question, answer ,context_seq_length, question_seq_length, answer_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JbeFZdZavodV"
   },
   "outputs": [],
   "source": [
    "train_data = Question_Answer(df, tokenizer, glove)\n",
    "test_data  = Question_Answer(test_df, tokenizer, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AJmhKI4fxiuB"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True,collate_fn=padding_and_masking)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=True,collate_fn=padding_and_masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eLtip209xwcQ"
   },
   "outputs": [],
   "source": [
    "context,question,answer,context_seq_length,question_seq_length,answer_seq_length = next(iter(train_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIDAF(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size):\n",
    "        super(BIDAF,self).__init__()\n",
    "        self.embedding = None;\n",
    "        self.lstm = nn.LSTM(embedding_dim,hidden_size,bidirectional=True)\n",
    "        self.lstm1=nn.LSTM(embedding_dim*4, embedding_dim, bidirectional=True, num_layers=2)\n",
    "        self.lstm2= nn.LSTM(embedding_dim*2, embedding_dim, bidirectional=True)\n",
    "        self.output1= nn.Linear(embedding_dim*6,1)\n",
    "        self.output2=nn.Linear(embedding_dim*6,1)\n",
    "        \n",
    "    def forward(self,context, question):\n",
    "        que_emb = self.embedding(question)\n",
    "        \n",
    "        outq,(hq,cq) = self.lstm(que_emb)\n",
    "        \n",
    "        con_emb=self.embedding(context)\n",
    "        \n",
    "        outc,(hc,cc)=self.lstm(con_emb)\n",
    "        \n",
    "        matrix=torch.bmm(outc,outq.transpose(1, 2))\n",
    "        \n",
    "        C2Q = nn.functional.softmax(matrix, dim=-1)\n",
    "        \n",
    "        Q2C = nn.functional.softmax(torch.max(matrix,dim=-1)[0],dim=-1)\n",
    "        \n",
    "        b=torch.bmm(C2Q,que_emb)\n",
    "        \n",
    "        J=torch.bmm(torch.unsqueeze(Q2C,1),con_emb)\n",
    "        \n",
    "        J=J.repeat(1,con_emb.shape[1],1)\n",
    "        \n",
    "        F = torch.cat([con_emb, b, torch.mul(con_emb,b), torch.mul(con_emb, J)],dim=2)\n",
    "        \n",
    "        out1,(h1,c1)= self.lstm1(F)\n",
    "        out2,(h2,c2)=self.lstm2(out1)\n",
    "        \n",
    "        p1=self.output1(torch.cat([F,out1],dim=2))\n",
    "        \n",
    "        p1=p1.squeeze()\n",
    "        \n",
    "        p2=self.output2(torch.cat([F,out2],dim=2))\n",
    "        \n",
    "        p2=p2.squeeze()\n",
    "        \n",
    "        return p1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0245, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "context,question,answer,context_seq_length,question_seq_length,answer_seq_length = next(iter(train_loader))\n",
    "num_embeddings=len(vocab) \n",
    "embedding_dim=100\n",
    "hidden_size=100\n",
    "bidaf=BIDAF(num_embeddings,embedding_dim,100)\n",
    "bidaf.embedding=nn.Embedding.from_pretrained(word_embedding)\n",
    "p1,p2=bidaf.forward(context,question)\n",
    "\n",
    "start_index=[];\n",
    "end_index=[];\n",
    "answer_seq_length=answer_seq_length-1;\n",
    "            \n",
    "for ans,index in zip(answer,answer_seq_length):\n",
    "    end_index.append(int(ans[index]))\n",
    "    start_index.append(int(ans[0]))\n",
    "            \n",
    "start_index=torch.tensor(start_index)\n",
    "end_index=torch.tensor(end_index)\n",
    "\n",
    "z=nn.functional.cross_entropy(p1,start_index)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_neurons = 100\n",
    "vocabulary_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "model=BIDAF(num_embeddings,embedding_dim,hidden_layer_neurons)\n",
    "model.embedding=nn.Embedding.from_pretrained(word_embedding)\n",
    "# Cross-Entropy loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_BIDAF(model, train_loader):\n",
    "\n",
    "    train_loss = 0.\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        context, question, answer ,context_seq_length, question_seq_length, answer_seq_length  = batch\n",
    "        p1,p2 = model(context, question)\n",
    "        start_index=[];\n",
    "        end_index=[];\n",
    "        answer_seq_length=answer_seq_length-1;\n",
    "            \n",
    "        for ans,index in zip(answer,answer_seq_length):\n",
    "            end_index.append(int(ans[index]))\n",
    "            start_index.append(int(ans[0]))\n",
    "            \n",
    "        start_index=torch.tensor(start_index)\n",
    "        end_index=torch.tensor(end_index)\n",
    "        \n",
    "\n",
    "        \n",
    "        loss = nn.functional.cross_entropy(p1, start_index) + nn.functional.cross_entropy(p2, end_index)\n",
    "\n",
    "        loss.backward()\n",
    "    \n",
    "    \n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = train_and_evaluate_BIDAF(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.255741834640503"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_evaluate_BIDAF(model, test_loader):\n",
    "\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            context, question, answer ,context_seq_length, question_seq_length, answer_seq_length  = batch\n",
    "            p1,p2 = model(context, question)\n",
    "            start_index=[];\n",
    "            end_index=[];\n",
    "            answer_seq_length=answer_seq_length-1;\n",
    "            \n",
    "            for ans,index in zip(answer,answer_seq_length):\n",
    "                end_index.append(int(ans[index]))\n",
    "                start_index.append(int(ans[0]))\n",
    "            \n",
    "            start_index=torch.tensor(start_index)\n",
    "            end_index=torch.tensor(end_index)\n",
    "        \n",
    "\n",
    "        \n",
    "            loss = nn.functional.cross_entropy(p1, start_index) + nn.functional.cross_entropy(p2, end_index)\n",
    "\n",
    "            \n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = test_and_evaluate_BIDAF(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.94553804397583"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model,context,question,answer):\n",
    "    p1,p2=model(context,question);\n",
    "    p1=torch.argmax(p1,dim=-1);\n",
    "    p2=torch.argmax(p2,dim=-1);\n",
    "    c=[]\n",
    "    for i in context[0]:\n",
    "        if(i!=0):\n",
    "            c.append(vocab[i])\n",
    "    print(' '.join(c))\n",
    "    print(' ')\n",
    "    q=[]\n",
    "    for i in question[0]:\n",
    "        if(i!=0):\n",
    "            q.append(vocab[i])\n",
    "    print(' '.join(q))\n",
    "    print(' ')\n",
    "    a=[]\n",
    "    for i in answer[0]:\n",
    "        if(i!=0):\n",
    "            a.append(vocab[i])\n",
    "    print(' '.join(a))\n",
    "    print(' ')\n",
    "    \n",
    "    print([vocab[p1[0]],vocab[p2[0]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season . the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24–10 to earn their third super bowl title . the game was played on february 7 , 2016 , at levi 's stadium in the san francisco bay area at santa clara , california . as this was the 50th super bowl , the league emphasized the \" golden anniversary \" with various gold - themed initiatives , as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ) , so that the logo could prominently feature the arabic numerals 50 .\n",
      " \n",
      "who won super bowl 50 ?\n",
      " \n",
      "denver broncos\n",
      " \n",
      "['denver', 'broncos']\n"
     ]
    }
   ],
   "source": [
    "context,question,answer,context_seq_length,question_seq_length,answer_seq_length = next(iter(train_loader))\n",
    "prediction(model,context,question,answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season . the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24–10 to earn their third super bowl title . the game was played on february 7 , 2016 , at levi 's stadium in the san francisco bay area at santa clara , california . as this was the 50th super bowl , the league emphasized the \" golden anniversary \" with various gold - themed initiatives , as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ) , so that the logo could prominently feature the arabic numerals 50 .\n",
      " \n",
      "what team was the nfc champion ?\n",
      " \n",
      "carolina panthers\n",
      " \n",
      "['denver', 'national']\n"
     ]
    }
   ],
   "source": [
    "context,question,answer,context_seq_length,question_seq_length,answer_seq_length = next(iter(train_loader))\n",
    "prediction(model,context,question,answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season . the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24–10 to earn their third super bowl title . the game was played on february 7 , 2016 , at levi 's stadium in the san francisco bay area at santa clara , california . as this was the 50th super bowl , the league emphasized the \" golden anniversary \" with various gold - themed initiatives , as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ) , so that the logo could prominently feature the arabic numerals 50 .\n",
      " \n",
      "which nfl team won super bowl 50 ?\n",
      " \n",
      "denver broncos\n",
      " \n",
      "['denver', 'national']\n"
     ]
    }
   ],
   "source": [
    "context,question,answer,context_seq_length,question_seq_length,answer_seq_length = next(iter(train_loader))\n",
    "prediction(model,context,question,answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BiDAF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
